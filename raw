#!/usr/bin/env python
# vim: set ft=python

import argparse
import sys
import asyncio
import os
import json
import re

try:
    import aiohttp
except ModuleNotFoundError:
    print(
        "Fail to import aiohttp module, please install it with `sudo pacman -S python-aiohttp`"
    )

try:
    import aiofiles
except ModuleNotFoundError:
    print(
        "Fail to import `aiofiles` module, please install it with `sudo pacman -S python-aiofiles`"
    )

ANSI_GREEN = "\033[0;32m"
ANSI_YELLOW = "\033[0;33m"
ANSI_RED = "\033[0;31m"
ANSI_RESET = "\033[0m"
ANSI_BOLD = "\033[1m"
ANSI_UNDERLINE = "\033[4m"
DISABLE_EMOJI = True

NOQEMU_LIST_URL = "https://raw.githubusercontent.com/felixonmars/archriscv-packages/master/qemu-user-blacklist.txt"

# Display underline style text by ANSI escape code
def ansi_underline(s: str) -> str:
    return f"{ANSI_UNDERLINE}{s}{ANSI_RESET}"


# Display underline style text by ANSI bold code
def ansi_bold(s: str) -> str:
    return f"{ANSI_BOLD}{s}{ANSI_RESET}"


# Try to get environment variable, if get None, return default string
def getenv_or(key: str, default: str) -> str:
    val = os.getenv(key)
    if val is None:
        return default

    return val


# Print text with error prefix
def eprint(fmt: str, *args, **kwargs):
    emoji = "âš ï¸"
    prefix = f"{ANSI_RED}{ANSI_BOLD}ERROR{ANSI_RESET}"
    if not DISABLE_EMOJI:
        prefix = f"{emoji}{prefix}"
    else:
        prefix = f"[{prefix}]"
    print(f"{prefix} {fmt}", *args, file=sys.stderr, **kwargs)


# Print text with warning prefix
def warn(fmt: str, *args, **kwargs):
    emoji = "ðŸ’¡"
    prefix = f"{ANSI_YELLOW}{ANSI_BOLD}WARN{ANSI_RESET}"
    if not DISABLE_EMOJI:
        prefix = f"{emoji}{prefix}"
    else:
        prefix = f"[{prefix}]"
    print(f"{prefix} {fmt}", *args, **kwargs)


# Print text with info prefix
def info(fmt: str, *args, **kwargs):
    emoji = "ðŸŸ¢"
    prefix = f"{ANSI_GREEN}{ANSI_BOLD}INFO{ANSI_RESET}"
    if not DISABLE_EMOJI:
        prefix = f"{emoji}{prefix}"
    else:
        prefix = f"[{prefix}]"
    print(f"{prefix} {fmt}", *args, **kwargs)


# A argument parser builder function
def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="An asp & archbuild & rsync wrapper script"
    )
    # -s/--server
    parser.add_argument(
        "-s",
        "--server",
        metavar="[Remote Server]",
        dest="server",
        help="Specify which server to run the build process",
    )
    # --update-server
    parser.add_argument(
        "--update-server",
        dest="force_update_server",
        action="store_true",
        help="Run server test only. This will overwrite the context file.",
    )
    # -r/--rebuild
    parser.add_argument(
        "-r",
        "--rebuild",
        dest="rebuild_mode",
        action="store_true",
        help="Enable rebuild mode: send local PKGBUILD file to remote for rebuild",
    )
    # -c/--clean
    parser.add_argument(
        "-c",
        "--clean",
        dest="clean_mode",
        action="store_true",
        help="Enable clean mode: Clean local and remote package file",
    )
    # --disable-emoji
    parser.add_argument(
        "--fancy",
        dest="fancy_mode",
        action="store_true",
        help="Use emoji as logging prefix",
    )
    # -p/--prepare
    parser.add_argument(
        "-p",
        "--prepare",
        dest="prepare_mode",
        action="store_true",
        help="Enable prepare mode: Run asp checkout on remote server only",
    )
    # --test
    parser.add_argument(
        "--test",
        dest="test_func",
        metavar="Function Params",
        nargs="*",
        help="Debug options, user should never use this",
    )

    parser.add_argument(
        dest="pkgname", metavar="[Package Name]", nargs="?", default="<NONE>"
    )

    return parser.parse_args()


# Return boolean value to indicate an executable is found on local machine
async def has_exec(exec: str) -> bool:
    script = f"command -v {exec}"

    proc = await asyncio.create_subprocess_shell(
        script,
        stdout=asyncio.subprocess.DEVNULL,
        stderr=asyncio.subprocess.DEVNULL,
    )

    await proc.communicate()

    if proc.returncode != 0:
        return False

    return True


# try_get_context try to open the `.ctx.json` file. If the file exist, it returns
# the content. If the file is not exist or open function throw
def try_get_context() -> (str | None):
    try:
        with open(".ctx.json", "r") as file:
            content = file.read()
            return content
    except FileNotFoundError:
        return None
    except:
        eprint(f"Fail to open .ctx.json file")
        raise


# Use uptime command to get the load for the specified server.
# Return None if it fail to run `uptime` command on the given ssh server.
# Return a tuple pair with server name and current load if successfully run the command.
async def test_server(server: str, debug=False) -> tuple[str, float] | None:
    cmd = f"/usr/bin/ssh {server} uptime"
    if debug:
        warn(f"Testing server: {server}")
    proc = await asyncio.create_subprocess_shell(
        cmd,
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.PIPE,
    )
    stdout, stderr = await proc.communicate()
    if proc.returncode != 0:
        eprint(
            f"Fail to get uptime information from server: {server}\n\tErr: {stderr.decode()}"
        )
        return None

    output = stdout.decode()
    load = float(output.split(",").pop().strip())
    return (server, load)


# Asynchronously run load test on the given servers.
# Use environment variable `RVSERVERS` to update the server list.
# For example:
#   RVSERVERS="luxio,shinx" raw --update-server
async def get_server(force=False) -> str:
    # if force update, skip this
    if not force:
        # if we have .ctx.json file at local
        context = try_get_context()
        if not context is None:
            context = json.loads(context)
            return context["server"]

    # test
    server_list = getenv_or("RVSERVERS", "luxio,shinx,minun")
    server_list = server_list.split(",")

    info(f"Pending test server: {server_list}")
    wg = []
    for server in server_list:
        task = asyncio.create_task(test_server(server))
        wg.append(task)

    lowest = 0.00
    select = ""
    for task in wg:
        server, load = await task
        if lowest == 0.00 or load < lowest:
            lowest = load
            select = server

    return select


# A test handler that can help debugging single function
# Usage: ./raw --test fn a b c
# If you are going to test async function:
# ./raw --test async fn a b c
async def handle_test(args: list[str]) -> int:
    length = len(args)
    if length < 1:
        eprint("No keyword is specified")
        return 1

    keyword = args[0]

    is_async = False
    if keyword == "await":
        is_async = True

    if is_async:
        if length < 2:
            eprint("No function name given")
            return 1
        func = args[1]
        params = args[2:]
        to_run = f"{func}({','.join(params)})"
        print(f"Going to await {to_run}")
        await eval(to_run)
    else:
        params = args[1:]
        eval(f"{keyword}({','.join(params)})")

    return 0


# An object to store the current build context.
# Initialize it with server and package name.
# Or initialize it with the JSON file path.
class BuildContext:
    def __init__(
        self,
        server: str | None = None,
        package: str | None = None,
        file: str | None = None,
    ) -> None:
        if file != None:
            with open(file, "r") as f:
                s = f.read()
                ctx = json.loads(s)

            self.server = ctx["server"]
            self.package = ctx["server"]
            self.pkgpath = ctx["pkgpath"]
            self.cachepath = ctx["cachepath"]
            self.noqemu_list_file = ctx["noqemu_list_file"]
        else:
            if server is None or package is None:
                eprint("BuildContext is init without enought argument!")
                sys.exit(1)
            self.server = server
            self.package = package

    async def _get_noqemu_list(self) -> str | None:
        info("Checking noqemu blacklist")
        # If we have local version
        if os.path.exists("noqemu-list.txt"):
            async with aiofiles.open("noqemu-list.txt", "r") as file:
                return await file.read()

        # If not, we download one
        async with aiohttp.ClientSession() as session:
            async with session.get(NOQEMU_LIST_URL) as response:
                if response.status != 200:
                    warn("Fail to download noqemu list. Skip noqemu check")
                    return None

                body = await response.text()
                info(
                    "Successfully downloaded noqemu list, saving to noqemu-list.txt file"
                )
                async with aiofiles.open("noqemu-list.txt", "w") as file:
                    await file.write(body)

                return body

    # Prepare the build environment for building the packege with the below steps:
    #   1. mkdir -p ${RVPKGPATH:-/home/user/riscv/package}
    #   2. mkdir -p ${RVCACHEPATH:-/home/user/.cache/rvpkgcache}
    #   3. asp update
    #   4. if [[ -d $RVPKGPATH/$PACKAGE ]]; then asp checkout $PACKAGE; fi
    #   5. rsync $SERVER/$RVPKGPATH/$PACKAGE/trunk/PKGBUILD .
    #   6. setconf $RVPKGPATH/$PACKAGE/trunk/PKGBUILD arch "(riscv64 x86_64)"
    async def prepare(self) -> None:
        get_qemu_task = asyncio.create_task(self._get_noqemu_list())
        home_dir = await self._ssh("echo $HOME")

        pkgpath = getenv_or("RVPKGPATH", f"{home_dir}/riscv/packages")
        self.cachepath = getenv_or("RVCACHEPATH", f"{home_dir}/.cache/rvpkgcache")

        await self._ssh(f"mkdir -p {pkgpath}")
        info(f"PKGBUILD Path: {ansi_underline(pkgpath)}")

        await self._ssh(f"mkdir -p {self.cachepath}")
        info(f"Package Cache: {ansi_underline(self.cachepath)}")

        info("Running asp update")
        await self._ssh("asp update")

        info("Preparing PKGBUILD file")
        if await self._ssh(f"test -d {pkgpath}/{self.package}", True) is None:
            info(f"Downloading {ansi_bold(self.package)} PKGBUILD file")
            await self._ssh(f"cd {pkgpath} && asp checkout {self.package}")

        self.pkgpath = f"{pkgpath}/{self.package}"

        info("Save a copy of the PKGBUILD to local")
        if not os.path.exists("PKGBUILD"):
            await self._pull_file(f"{self.pkgpath}/trunk/PKGBUILD")

        await self._ssh(
            f'cd {self.pkgpath}/trunk && setconf PKGBUILD arch "(riscv64 x86_64)"'
        )

        noqemu_list = await get_qemu_task
        if noqemu_list is None:
            return

        if noqemu_list.find(self.package) == -1:
            return

        arch = await self._ssh("uname -m")
        if arch is None:
            return

        if arch.strip() != "riscv64":
            warn(
                "This package is in noqemu black list, but you are not building it on RISC-V board."
            )
            confirm = input("Do you still want to continue? [y/N]: ")
            if confirm != "y" or confirm != "Y":
                info("Exit by user")
                sys.exit(1)

    # The main function that should be called by outside to start an actual package build
    async def build(self) -> int:
        info("Start building")
        code = await self._archbuild()
        if code == 0:
            info(f"Package {ansi_bold(self.package)} is successfully built!")
            return 0

        await self._after_build()
        return 1

    # Run a command and return its stdout string. If the param `expect_fail` is True,
    # It return None. If the command is not expect to fail, it print the error message
    # to the stdout.
    async def _ssh(self, cmd: str, expect_fail=False) -> str | None:
        proc = await asyncio.create_subprocess_shell(
            f"/usr/bin/ssh {self.server} '{cmd}'",
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
        )
        stdout, stderr = await proc.communicate()
        if proc.returncode == 0:
            return stdout.decode().strip()
        else:
            if not expect_fail:
                eprint(f"Fail to run command {cmd}\n\nGet error:\n\t{stderr.decode()}")
            return None

    # Send a file to the current package's trunk path
    async def _send_file(self, file: str) -> None:
        proc = await asyncio.create_subprocess_shell(
            f"/usr/bin/rsync -az {file} {self.server}:{self.pkgpath}/trunk/",
            stdout=asyncio.subprocess.DEVNULL,
            stderr=asyncio.subprocess.PIPE,
        )

        _, stderr = await proc.communicate()
        if proc.returncode != 0:
            eprint(f"Fail to send file {file}\n\nGet error:\n\t{stderr.decode()}")
            return None

    # Pull a file from the given path
    async def _pull_file(self, path: str) -> None:
        proc = await asyncio.create_subprocess_shell(
            f"/usr/bin/rsync -az {self.server}:{path} .",
            stdout=asyncio.subprocess.DEVNULL,
            stderr=asyncio.subprocess.PIPE,
        )

        _, stderr = await proc.communicate()
        if proc.returncode != 0:
            eprint(
                f"Fail to pull file from path {ansi_underline(path)}\n\nGet error:\n\t{stderr}"
            )

    # An infinite loop to read the stderr from given StreamReader.
    # If the stderr is about the gpg key error, it will return the missing gpg key finger print.
    async def _read_stderr(self, stream: asyncio.StreamReader | None) -> str | None:
        gpg_key_not_found_flag = re.compile(r"\(unknown public key ([0-9a-fA-F]+)\)")

        if stream is None:
            return None

        while True:
            # read line from stream
            line = await stream.readline()
            if not line:
                return None

            line = line.decode().strip()

            # redirect output to stdout
            print(line)

            # Test if current line is about gpg key missing
            match = gpg_key_not_found_flag.search(line)
            if match:
                info("GPG key not found on local, try downloading...")
                await self._ssh("gpg --recv-keys " + match.group(1))
                info("Downloaded, rebuild the package...")
                return match.group(1)

    # A wrapper function to run the archbuild command. It will retry the archbuild command
    # if the error is gpg key missing error.
    async def _archbuild(self) -> int | None:
        change_dir = f"cd {self.pkgpath}/trunk"
        build_cmd = f'{change_dir};extra-riscv64-build -- -d "{self.cachepath}:/var/cache/pacman/pkg/"'
        proc = await asyncio.create_subprocess_shell(
            f"/usr/bin/ssh {self.server} '{build_cmd}'",
            stderr=asyncio.subprocess.PIPE,
        )

        gpg_key = await self._read_stderr(proc.stderr)
        if gpg_key is not None:
            info("Waiting for previous process finish its jobs")
            await proc.wait()

            info("Restarting new build process")
            proc = await asyncio.create_subprocess_shell(
                f"/usr/bin/ssh {self.server} '{build_cmd}'",
            )

        code = await proc.wait()
        return code

    # Download build log if the log is exist
    async def _download_log(self) -> None:
        if await self._ssh(f"test -e {self.pkgpath}/trunk/*.log", True) is not None:
            info("Downloading log")
            await self._pull_file(f"{self.pkgpath}/trunk/*.log")
        else:
            info("No log found for this package")

    def _save(self):
        info("Saving context")
        jstr = json.dumps(self.__dict__)
        with open(".ctx.json", "w") as f:
            f.write(jstr)

    # Download remote PKGBUILD and build log
    async def _after_build(self):
        eprint(f"Fail to build package {self.package}")

        info("Pulling remote PKGBUILD")
        if not os.path.exists("PKGBUILD"):
            await self._pull_file(f"{self.pkgpath}/trunk/PKGBUILD")
        else:
            ok = input(
                "There is a PKGBUILD at local already, do you want to cover it? [y/N]: "
            )
            if ok == "y" or ok == "Y":
                info("Downloading PKGBUILD")
                await self._pull_file(f"{self.pkgpath}/trunk/PKGBUILD")

        # Download log if it exist
        await self._download_log()

        # Save build context to json file
        self._save()
        return 1


# A handler for build process
async def handle_build(server: str, package: str, prepare=False, rebuild=False) -> int:
    ctx: BuildContext

    info("Try loading build context")
    # Read context when no package name is given
    if package == "<NONE>":
        info("No package name specified, loading local context!")
        if not os.path.exists(".ctx.json"):
            eprint("No context file found, and no package name is given, abort!")
            return 1
        ctx = BuildContext(file=".ctx.json")
    else:
        ctx = BuildContext(server=server, package=package)

    # prepare the build environment
    await ctx.prepare()

    # Do not run build script when enable prepare mode
    if prepare:
        info("Prepare jobs is done, exiting...")
        return 0

    # sending local PKGBUILD file to remote
    if rebuild:
        if os.path.exists("PKGBUILD"):
            info("Sending local PKGBUILD to remote")
            await ctx._send_file("PKGBUILD")
        else:
            eprint("No PKGBUILD file found on local")

    # Finally start the build
    return await ctx.build()


async def handle_clean() -> int:
    return 0


# The script main entry
async def run() -> int:
    # parse command line argument
    args = parse_args()

    if args.fancy_mode:
        global DISABLE_EMOJI
        DISABLE_EMOJI = False

    # For debugging
    if args.test_func is not None:
        code = await handle_test(args.test_func)
        return code

    # Checking dependencies
    has_ssh = await has_exec("ssh")
    if not has_ssh:
        eprint("No ssh found on this machine, aborted")
        return 1
    has_rsync = await has_exec("rsync")
    if not has_rsync:
        eprint("No rsync found on this machine, aborted")
        return 1

    # Benchmark servers
    server = ""
    if args.server is None:
        server = await get_server(force=args.force_update_server)
    else:
        server = args.server

    info(f"Selected Server: {ANSI_GREEN}{ANSI_BOLD}{server}{ANSI_RESET}")

    # Do not perform build when using --update-server flag
    if args.force_update_server:
        return 0

    # Do not perform build when using --clean flag
    if args.clean_mode:
        return await handle_clean()

    return await handle_build(
        server,
        args.pkgname,
        args.prepare_mode,
        args.rebuild_mode,
    )


if __name__ == "__main__":
    exit_id = asyncio.run(run())
    sys.exit(exit_id)
